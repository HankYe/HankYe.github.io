<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
	<meta charset="UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<title>Hancheng Ye – Personal Profile</title>
	<meta name="author" content="Hancheng Ye" />

	<link rel="stylesheet" type="text/css" href="css/bootstrap-grid.min.css"/>
	<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css"/>
	<link rel="stylesheet" type="text/css" href="bower_components/normalize-css/normalize.css" />
	<link rel="stylesheet" href="ajax/libs/animate.css/3.5.2/animate.min.css">
	<link rel="stylesheet" type="text/css" href="css/styles.css" />


	<script src="js/jquery-1.11.2.min.js"></script>
	<script src="js/jquery.easing.1.3.js"></script>
	<script src="js/main.js?version=1.0.0"></script>
	<script src="js/jquery.scrollex.min.js"></script>
	<script src="js/scroll.js"></script>
	<script>document.documentElement.className = 'js';</script>
	
</head>
<body class="webgl-bg loading">
	<div class="hider">
		<div class="hider-layer1">
		</div>
	</div>
	<canvas id="webgl"></canvas>
	<header class="primary-nav">
		<div class="nav-container">
			<nav class="menu-nav">
				<ul>
					<li><a href="#top"><span>Welcome</span></a></li>
					<li><a href="#about"><span>About Me</span></a></li>
					<li><a href="#news"><span>News</span></a></li>
					<li><a href="#works"><span>Works</span></a></li>
					<li><a href="#contact me"><span>Contact Me</span></a></li>
				</ul>
			</nav>
		</div>
		<div class="logo-container">
			<div class="menu-icon-container" data-click-state="1">
				<span class="menu-icon"></span>
			</div>
            <a href="#top" title="Hancheng Ye" class="logo">
				<svg width="67px" height="58px" viewBox="0 0 67 58" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
					<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
						<g id="PH-Logo" transform="translate(-696.000000, -79.000000)" fill="#FFFFFF">
							<g id="Logo-inner" transform="translate(696.000000, 79.000000)">
								<filter id="svg_blur">
										<feGaussianBlur stdDeviation="0.6" in="SourceGraphic"/>
								</filter>
								<defs>
									<linearGradient id="LinearGradient"
 					                		x1="0%" y1="0%"
                    						x2="0%" y2="100%"
                    						spreadMethod="pad">
      								<stop offset="0%"   stop-color="#01010F" stop-opacity="1"/>
      								<stop offset="100%" stop-color="#0C0CBA" stop-opacity="1"/>
    								</linearGradient>
  								</defs>
								<path filter="url(#svg_blur)" d="m1.18795,28.817893 l13.845374,-27.739667 l36.920994,0 l13.845369,27.739667 l-13.845369,27.739667 l-36.920994,0 l-13.845374,-27.739667 z" id="Shape"></path>
								<path filter="url(#svg_blur)" d="m7.490451,28.415941 l11.105652,-22.71684 l29.61507,0 l11.105648,22.716848 l-11.105648,22.716848 l-29.61507,0 l-11.105652,-22.716848 z" style="fill:url(#LinearGradient)" id="Shape"></path>
								<rect filter="url(#svg_blur)" transform="rotate(28 33.468647003173814,28.60523223876953) " stroke="#000" id="svg_22" height="55.815801" width="5.47944" y="0.697331" x="30.728928" stroke-width="0" fill="#ffffff"/>
								<path filter="url(#svg_blur)" d="m4.135434,30.868343l4.520538,-5.47944l18.082152,0l-4.520538,5.47944l-18.082152,0z" id="Shape"></path>
								<path filter="url(#svg_blur)" d="m44.11252,27.467668l3.698623,-5.47944l14.794491,0l-3.698623,5.47944l-14.794491,0z" id="Shape"></path>
								<path filter="url(#svg_blur)" transform="rotate(21 35.78774261474609,47.602386474609375) " stroke="#f79d02" id="svg_25" d="m32.774221,53.190381l1.20541,-11.175993l4.821638,0l-1.20541,11.175993l-4.821638,0z" stroke-width="0" fill="#ffffff"/>
							</g>
						</g>
					</g>
				</svg>
			</a>
			<nav class="main-nav-full">
				<ul>
					<li><a href="#top" data-letters="Welcome">Welcome</a></li>
					<li><a href="#about" data-letters="About Me">About Me</a></li>
					<li><a href="#news" data-letters="News">News</a></li>
					<li><a href="#works" data-letters="Works">Works</a></li>
					<li><a href="#contact me" data-letters="Contact Me">Contact Me</a></li>
				</ul>
			</nav>
		</div>

    </header>
    <!-- Theme toggle placed outside transformed header to ensure clickability -->
    <button id="theme-toggle" class="theme-toggle" type="button" tabindex="0" aria-label="Toggle light/dark mode" title="Toggle light/dark mode" aria-pressed="false"></button>


	<main class="main" id="top">
		<!--The cover of the web, which contain the logo in the top middle, and the title 'Hancheng Ye'.-->
		<header class="content content-header">
			<div class="logo-2">
				<a href="#top" title="Hancheng Ye" class="logo">
					<svg width="67px" height="58px" viewBox="0 0 67 58" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
						<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
							<g id="PH-Logo" transform="translate(-696.000000, -79.000000)" fill="#FFFFFF">
								<g id="Logo-inner" transform="translate(696.000000, 79.000000)">
									<filter id="svg_blur">
										<feGaussianBlur stdDeviation="0.6" in="SourceGraphic"/>
									</filter>
									<path filter="url(#svg_blur)" d="m1.18795,28.817893 l13.845374,-27.739667 l36.920994,0 l13.845369,27.739667 l-13.845369,27.739667 l-36.920994,0 l-13.845374,-27.739667 z" id="Shape"></path>
									<path filter="url(#svg_blur)" d="m7.490451,28.415941 l11.105652,-22.71684 l29.61507,0 l11.105648,22.716848 l-11.105648,22.716848 l-29.61507,0 l-11.105652,-22.716848 z" style="fill:url(#LinearGradient)" id="Shape"></path>
									<rect filter="url(#svg_blur)" transform="rotate(28 33.468647003173814,28.60523223876953) " stroke="#000" id="svg_22" height="55.815801" width="5.47944" y="0.697331" x="30.728928" stroke-width="0" fill="#ffffff"/>
									<path filter="url(#svg_blur)" d="m4.135434,30.868343l4.520538,-5.47944l18.082152,0l-4.520538,5.47944l-18.082152,0z" id="Shape"></path>
									<path filter="url(#svg_blur)" d="m44.11252,27.467668l3.698623,-5.47944l14.794491,0l-3.698623,5.47944l-14.794491,0z" id="Shape"></path>
									<path filter="url(#svg_blur)" transform="rotate(21 35.78774261474609,47.602386474609375) " stroke="#f79d02" id="svg_25" d="m32.774221,53.190381l1.20541,-11.175993l4.821638,0l-1.20541,11.175993l-4.821638,0z" stroke-width="0" fill="#ffffff"/>
								</g>
							</g>
						</g>
					</svg>
				</a>
			</div>
			<div class="content-top">
				<div class="content-top-container">
					<h1 class="block">Hancheng Ye</h1>
					<h4 class="block">Ph.D. Student in Duke University</h4>
				</div>
			</div>
		</header>
		<section class="content content-main">

			<!-- SECTION ABOUT -->
			<div class="content-section content-about" id="about">
				<div class="container mt-5 pt-5">
					<div class="row">
						<div class="col-xs-12 col-md-12">
							<h3 class="quote-animation">
								<span class="animText animText-1 ">“Welcome to my world!” </span>
							</h3>
						</div>
					</div>
					<div class="row mt-5 pt-5 about-text">
						<div class="col-md-12 text-content3">
							<h4>About me:</h4>
								<ul>
									<li>Hi, I am a second year PhD student at Duke ECE, advised by <a href="https://cei.pratt.duke.edu/people/yiran-chen" target="_blank">Prof. Yiran Chen</a>. Previously, I obtained my M.S. and B.E. from School of Information Science and Technology, Fudan University, where I worked closely with <a href="https://eetchen.github.io/" target="_blank">Prof. Tao Chen</a> and <a href="https://bobrown.github.io/boZhang.github.io/" target="_blank">Dr. Bo Zhang</a> (Shanghai Artificial Intelligence Laboratory) in the area of efficient deep learning (specifically, model compression for multi-task learning). My current research interests lie mainly in <b><i>Machine Learning System</i></b>, where I work closely with <a href="https://danyangzhuo.com/" target="_blank">Prof. Danyang Zhuo</a> on the <b><i>efficient multi-agent system design</i></b>. In the summer before coming to Duke, I was very lucky to work with <a href="https://zhijianliu.com/" target="_blank">Dr. Zhijian Liu</a> on the efficient diffusion acceleration and <a href="https://bobrown.github.io/boZhang.github.io/" target="_blank">Dr. Bo Zhang</a> on multimodal learning. I interned at Shanghai Artificial Intelligence Laboratory and MIT HAN Lab.</li>
									<li>For more information, please click <a href="./file/CV_HANCHENG_Ye_20251101.pdf" target="_blank">here</a>.</li>
									<li>Social media: 
										<a href="https://scholar.google.com/citations?user=I9rLoV8AAAAJ" target="_blank" rel="noopener">Google Scholar</a> · 
										<a href="https://www.linkedin.com/in/hancheng-ye-32161a167/" target="_blank" rel="noopener">LinkedIn</a> · 
										<a href="https://x.com/HankYe1" target="_blank" rel="noopener">X</a> · 
										<a href="https://github.com/HankYe" target="_blank" rel="noopener">GitHub</a>
									</li>
								</ul>
						</div>
					</div>

				</div>
			</div>
			<!-- END SECTION ABOUT -->
			<!-- SECTION NEWS -->
			<div class="content-section content-news" id="news">
				<div class="container">
					<h1>News</h1>
					<div class="content-news-inner mt-4">
                    <ul class="news-list">
						<li><b>Oct 2025</b> — We opensource the <a href="https://github.com/FastMAS/KVCOMM" target="_blank">KVCOMM codebase</a>. See <a href="https://arxiv.org/abs/2510.12872" target="_blank">Paper</a> and <a href="https://x.com/HankYe1/status/1984512446422532323" target="_blank">X Blog</a>.</li>
                        <li><b>Sep 2025</b> — Two papers are accepted to <b>NeurIPS 2025</b> (KVCOMM and GAINRL). Congrats to Qinsi!</li>
                        <li><b>Aug 2025</b> — ChartX &amp; ChartVLM is accepted to <b>T-IP 2025</b>. Congrats to Renqiu!</li>
                        <li><b>May 2025</b> — Two papers (SADA and CoreMatching) are accepted to <b>ICML 2025</b>. Congrats to Justin, Yixiao, and Qinsi!</li>
                        <li><b>Feb 2025</b> — BridgeNet is accepted to <b>T-PAMI 2025</b>. Congrats to Jingdong!</li>
                        <li><b>Jan 2025</b> — GeoX is accepted to <b>ICLR 2025</b>. Congrats to Renqiu and Mingsheng!</li>
                        <li><b>Oct 2024</b> — AdaptiveDiffusion is accepted to <b>NeurIPS 2024</b>, BDP-DARTS is accepted to <b>T-CSVT 2024</b>, and one paper is accepted to <b>Neurocomputing 2024</b>. Congrats to Chongjun and Peng!</li>
						<li><b>Aug 2024</b> — Start my Ph.D. journey in <b>Duke University</b>!</li>
                        <li><b>Jul 2024</b> — SPOT is accepted to <b>T-PAMI 2024</b>. Congrats to Xiangchao and Runjian!</li>
                        <li><b>Mar 2024</b> — OFB is accepted to <b>CVPR 2024</b>, and STP is accepted to <b>ECCV 2024</b>. Congrats to Shengji and Weihao!</li>
						<li><b>Mar 2023</b> — PAGCP is accepted to <b>T-PAMI 2023</b>.</li>
                    </ul>
					</div>
				</div>
			</div>
			<!-- END SECTION NEWS -->
			<!-- SECTION WORKS -->
			<div class="content-section content-works" id="works">
				<div class="container">
					<h1>Highlights</h1>
					<div class="content-works-inner mt-md-8 pt-md-8 animation ">
						<div class="row">
							<div class="col-xs-12 col-md-12 project project-jpeg">
                        <div class="kvcomm-container">
                            <a href="https://github.com/FastMAS/KVCOMM" target="_blank">
                                <object id="kvcomm-graphic" type="image/svg+xml" data="img/kvcomm.svg" class="img-fluid kvcomm-image" aria-label="KVCOMM">
                                  <img src="img/kvcomm.svg" alt="KVCOMM" class="img-fluid"/>
                                </object>
                            </a>
                            <span class="kvcomm-badge" aria-hidden="true">NeurIPS 2025</span>
                        </div>
                        <div class="kvcomm-caption">
                            <span class="kvcomm-caption-title"><b>NeurIPS 2025</b> — KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems</span>
                            <span class="kvcomm-caption-authors">
                                <b>Authors:</b>
                                <b>Hancheng Ye</b>, Zhengqi Gao, Mingyuan Ma, Qinsi Wang, Yuzhe Fu, Ming-Yu Chung, Yueqian Lin, Zhijian Liu, Jianyi Zhang, Danyang Zhuo, Yiran Chen.
                                <span class="kvcomm-links kvcomm-nobr">
                                    <a class="kvcomm-caption-link" href="https://github.com/FastMAS/KVCOMM" target="_blank">GitHub</a>
                                    <a class="kvcomm-caption-link" href="https://arxiv.org/abs/2510.12872" target="_blank">Paper</a>
                                </span>
                            </span>
                        </div>
							</div>
						</div>
						<!-- ChartX & ChartVLM as the second highlight -->
						<div class="row">
							<div class="col-xs-12 col-md-12 project project-chartx">
								<div class="kvcomm-container">
									<a href="https://github.com/Alpha-Innovator/ChartVLM" target="_blank" rel="noopener" class="cover">
										<picture>
											<source type="image/jpg" srcset="img/chartx.jpg" />
											<img src="img/chartx.jpg" alt="ChartX &amp; ChartVLM" onload="this.closest('.cover').classList.add('loaded');" onerror="var c=this.closest('.cover'); if(c){c.classList.add('error');} this.remove();" />
										</picture>
									</a>
									<span class="kvcomm-badge" aria-hidden="true">T-IP 2025</span>
								</div>
								<div class="kvcomm-caption">
									<span class="kvcomm-caption-title"><b>T-IP 2025</b> — ChartX &amp; ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning</span>
									<span class="kvcomm-caption-authors">
										<b>Authors:</b>
										Renqiu Xia*, <b>Hancheng Ye*</b>, Xiangchao Yan, Qi Liu, Hongbin Zhou, Zijun Chen, Botian Shi, Junchi Yan, and Bo Zhang.
										<span class="kvcomm-links kvcomm-nobr">
											<a class="kvcomm-caption-link" href="https://github.com/Alpha-Innovator/ChartVLM" target="_blank" rel="noopener">GitHub</a>
											<a class="kvcomm-caption-link" href="https://arxiv.org/pdf/2402.12185" target="_blank" rel="noopener">Paper</a>
										</span>
									</span>
								</div>
							</div>
						</div>
						<!-- SADA as the third highlight -->
						<div class="row">
							<div class="col-xs-12 col-md-12 project project-adiff">
								<div class="kvcomm-container">
									<a href="https://yixiao-wang-stats.github.io/SADA/" target="_blank" rel="noopener" class="cover">
										<picture>
											<img src="img/sada.jpg" alt="SADA: Stability-guided Adaptive Diffusion Acceleration" onload="this.closest('.cover').classList.add('loaded');" onerror="var c=this.closest('.cover'); if(c){c.classList.add('error');} this.remove();" />
										</picture>
									</a>
									<span class="kvcomm-badge" aria-hidden="true">ICML 2025</span>
								</div>
								<div class="kvcomm-caption">
									<span class="kvcomm-caption-title"><b>ICML 2025</b> — SADA: Stability-guided Adaptive Diffusion Acceleration</span>
									<span class="kvcomm-caption-authors">
										<b>Authors:</b>
										Ting Jiang*, Yixiao Wang*, <b>Hancheng Ye*</b>, Zishan Shao, Jingwei Sun, Jingyang Zhang, Zekai Chen, Jianyi Zhang, Yiran Chen, Hai Li.
										<span class="kvcomm-links kvcomm-nobr">
											<a class="kvcomm-caption-link" href="https://yixiao-wang-stats.github.io/SADA/" target="_blank" rel="noopener">GitHub</a>
											<a class="kvcomm-caption-link" href="https://openreview.net/pdf?id=ThMQfsBnje" target="_blank" rel="noopener">Paper</a>
										</span>
									</span>
								</div>
							</div>
						</div>
						<!-- Adaptive Diffusion as the fourth highlight -->
						<div class="row">
							<div class="col-xs-12 col-md-12 project project-adiff">
								<div class="kvcomm-container">
									<a href="https://github.com/Alpha-Innovator/AdaptiveDiffusion" target="_blank" rel="noopener" class="cover">
										<picture>
											<img src="img/adaptivediffusion.png" alt="Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy" onload="this.closest('.cover').classList.add('loaded');" onerror="var c=this.closest('.cover'); if(c){c.classList.add('error');} this.remove();" />
										</picture>
									</a>
									<span class="kvcomm-badge" aria-hidden="true">NeurIPS 2024</span>
								</div>
								<div class="kvcomm-caption">
									<span class="kvcomm-caption-title"><b>NeurIPS 2024</b> — Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy</span>
									<span class="kvcomm-caption-authors">
										<b>Authors:</b>
										<b>Hancheng Ye*</b>, Jiakang Yuan*, Renqiu Xia, Xiangchao Yan, Tao Chen, Junchi Yan, Botian Shi, Bo Zhang.
										<span class="kvcomm-links kvcomm-nobr">
											<a class="kvcomm-caption-link" href="https://jiakangyuan.github.io/AdaptiveDiffusion-project-page/" target="_blank" rel="noopener">GitHub</a>
											<a class="kvcomm-caption-link" href="https://arxiv.org/pdf/2410.09873" target="_blank" rel="noopener">Paper</a>
										</span>
									</span>
								</div>
							</div>
						</div>
                        <!-- OFB as the fifth highlight (before PAGCP) -->
                        <div class="row">
                            <div class="col-xs-12 col-md-12 project project-ofb">
                                <div class="kvcomm-container">
                                    <a href="img/ofb.pdf" target="_blank" rel="noopener" class="cover">
                                        <picture>
                                            <img src="img/ofb.jpg" alt="OFB: Once-for-Both (CVPR 2024)" onload="this.closest('.cover').classList.add('loaded');" onerror="var c=this.closest('.cover'); if(c){c.classList.add('error');} this.remove();" />
                                        </picture>
                                    </a>
                                    <span class="kvcomm-badge" aria-hidden="true">CVPR 2024</span>
                                </div>
                                <div class="kvcomm-caption">
                                    <span class="kvcomm-caption-title"><b>CVPR 2024</b> — Once for Both: Single Stage of Importance and Sparsity Search for Vision Transformer Compression</span>
                                    <span class="kvcomm-caption-authors">
                                        <b>Authors:</b>
                                        <b>Hancheng Ye</b>, Chong Yu, Peng Ye, Renqiu Xia, Yansong Tang, Jiwen Lu, Tao Chen, Bo Zhang.
                                        <span class="kvcomm-links kvcomm-nobr">
                                            <a class="kvcomm-caption-link" href="https://github.com/HankYe/Once-for-Both" target="_blank" rel="noopener">GitHub</a>
                                            <a class="kvcomm-caption-link" href="img/ofb.pdf" target="_blank" rel="noopener">Paper</a>
                                        </span>
                                    </span>
                                </div>
                            </div>
                        </div>

                        <!-- PAGCP highlight -->
                        <div class="row">
                            <div class="col-xs-12 col-md-12 project project-ofb">
                                <div class="kvcomm-container">
                                    <a href="https://github.com/HankYe/PAGCP" target="_blank" rel="noopener" class="cover">
                                        <picture>
                                            <img src="img/pagcp.jpg" alt="Performance-aware Approximation of Global Channel Pruning for Multitask CNNs" onload="this.closest('.cover').classList.add('loaded');" onerror="var c=this.closest('.cover'); if(c){c.classList.add('error');} this.remove();" />
                                        </picture>
                                    </a>
                                    <span class="kvcomm-badge" aria-hidden="true">T-PAMI 2023</span>
                                </div>
                                <div class="kvcomm-caption">
                                    <span class="kvcomm-caption-title"><b>T-PAMI 2023</b> — Performance-aware Approximation of Global Channel Pruning for Multitask CNNs</span>
                                    <span class="kvcomm-caption-authors">
                                        <b>Authors:</b>
                                        <b>Hancheng Ye</bb>, Bo Zhang, Tao Chen, Jiayuan Fan, and Bin Wang.
                                        <span class="kvcomm-links kvcomm-nobr">
                                            <a class="kvcomm-caption-link" href="https://github.com/HankYe/PAGCP" target="_blank" rel="noopener">GitHub</a>
                                            <a class="kvcomm-caption-link" href="https://arxiv.org/abs/2303.11923" target="_blank" rel="noopener">Paper</a>
                                        </span>
                                    </span>
                                </div>
                            </div>
                        </div>
                        <!-- All Publications -->
                        <div class="row mt-5 pt-4">
                            <div class="col-xs-12 col-md-12">
                                <h2 class="with-line2">Selected Publications</h2>
                                <div class="publications mt-4">
                                    <h3>Efficient Machine Learning</h3>
                                    <ul class="pub-list">
                                        <li><b>KVCOMM: Online Cross-context KV-cache Communication for Efficient LLM-based Multi-agent Systems.</b> <i>NeurIPS 2025</i>.
											<span class="pub-authors"><b>Hancheng Ye</b>, Zhengqi Gao, Mingyuan Ma, Qinsi Wang, Yuzhe Fu, Ming-Yu Chung, Yueqian Lin, Zhijian Liu, Jianyi Zhang, Danyang Zhuo, Yiran Chen.</span>
										</li>
                                        
										<li><b>SADA: Stability-guided Adaptive Diffusion Acceleration.</b> <i>ICML 2025</i>. 
											<span class="pub-authors">Ting Jiang*, Yixiao Wang*, <b>Hancheng Ye</b>*, Zishan Shao, Jingwei Sun, Jingyang Zhang, Zekai Chen, Jianyi Zhang, Yiran Chen, Hai Li.</span>
										</li>
                                        <li><b>AdaptiveDiffusion: Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy.</b> <i>NeurIPS 2024</i>.
											<span class="pub-authors"><b>Hancheng Ye</b>, Jiakang Yuan, Renqiu Xia, Xiangchao Yan, Tao Chen, Junchi Yan, Botian Shi, Bo Zhang.</span>
                                        </li>
                                        <li><b>OFB: Once for Both: Single Stage of Importance and Sparsity Search for Vision Transformer Compression.</b> <i>CVPR 2024</i>. 
											<span class="pub-authors"><b>Hancheng Ye</b>, Chong Yu, Peng Ye, Renqiu Xia, Yansong Tang, Jiwen Lu, Tao Chen, Bo Zhang.</span>
                                        </li>
                                        <li><b>PAGCP: Performance-aware Approximation of Global Channel Pruning for Multitask CNNs.</b> <i>T-PAMI 2023</i>. 
											<span class="pub-authors"><b>Hancheng Ye</b>, Bo Zhang, Tao Chen, Jiayuan Fan, Bin Wang.</span>
										</li>
										<li><b>GAINRL: Angles don't lie: Unlocking training-efficient RL through the model's own signals.</b> <i>NeurIPS 2025 (Spotlight)</i>. 
											<span class="pub-authors">Qinsi Wang, Jinhan Ke, <b>Hancheng Ye</b>, Yueqian Lin, Yuzhe Fu, Jianyi Zhang, Kurt Keutzer, Chenfeng Xu, Yiran Chen.</span>
										</li>
										<li><b>Efficient Architecture Search: Efficient architecture search via bi-level data pruning.</b> <i>T-CSVT 2024</i>.  
											<span class="pub-authors">Chongjun Tu, Peng Ye, Weihao Lin, <b>Hancheng Ye</b>, Chong Yu, Tao Chen, Baopu Li, & Wanli Ouyang.</span>
										</li>
										<li><b>Enhanced Sparsification: Enhanced sparsification via stimulative training.</b> <i>ECCV 2024</i>. 
											<span class="pub-authors">Shengji Tang, Weihao Lin, <b>Hancheng Ye</b>, Peng Ye, Chong Yu, Baopu Li, Tao Chen.</span>
										</li>
										<li><b>Sample-Centric Feature Generation: Sample-centric feature generation for semi-supervised few-shot learning.</b> <i>T-IP 2022</i>. 
											<span class="pub-authors">Bo Zhang, <b>Hancheng Ye</b>, Gang Yu, Bin Wang, Yike Wu, Jiayuan Fan, Tao Chen.</span>
										</li>
                                    </ul>
                                    <h3>Multimodal Learning</h3>
                                    <ul class="pub-list">
                                        <li><b>ChartX &amp; ChartVLM: A Versatile Benchmark and Foundation Model for Complicated Chart Reasoning.</b> <i>T-IP 2025</i>. Renqiu Xia*, <b>Hancheng Ye</b>*, Xiangchao Yan, Qi Liu, Hongbin Zhou, Zijun Chen, Botian Shi, Junchi Yan, Bo Zhang.</li>
										<li><b>GeoX: GeoX: Geometric Problem Solving Through Unified Formalized Vision-Language Pre-training.</b> <i>ICLR 2025</i>. Renqiu Xia*, Mingsheng Li*, <b>Hancheng Ye</b>, Wenjie Wu, Hongbin Zhou, Jiakang Yuan, Tianshuo Peng, Xinyu Cai, Xiangchao Yan, Bin Wang, Conghui He, Botian Shi, Tao Chen, Junchi Yan, Bo Zhang.</li>
									</ul>
                                </div>
                            </div>
                        </div>

						<!-- <div class="row">
							<div class="col-xs-12 col-md-4 project project-liver">
								<a href="https://github.com/HankYe/Evaluation-of-Liver-Fibrosis" target="_blank">
									<picture class="img-fluid">
										<img src="img/live-fibrosis.jpg" alt="" class="img-fluid"></img>
									</picture>
								</a>
							</div>
							<div class="col-xs-12 col-md-4 project project-opioid">
								<a href="https://github.com/HankYe/Solution-to-opioid-crisis" target="_blank">
									<picture class="img-fluid">
										<img src="img/opioid.jpg" alt="" class="img-fluid">
									</picture>
								</a>
							</div>
							<div class="col-xs-12 col-md-4 project project-CP">
								<a href="http://github.com/HankYe/Model-Pruning-for-SSD" target="_blank">
									<picture class="img-fluid">
										<img src="img/CP.jpg" alt="" class="img-fluid">
									</picture>
								</a>
							</div>
						</div> -->
					</div>
				</div>
			</div>
			<!-- END SECTION WORKS -->
		</section>
		<section class="content-related" id="contact me">
			<div class="container">
				<div class="row align-items-center">
					<div class="col-md-6 col-12">
					</div>
					<div class="col-md-6 content-contact col-12">
						<h1>Contact Me</h1>
                    <ul class="mt-5 contact-details">
                        <li>
                            <a href="mailto:hancheng.ye@duke.edu">
                                <b>Let’s Collaborate</b>
                                <span>Say hi at hancheng.ye@duke.edu — I’m especially interested in AI-based multi‑agent system optimization, efficient ML systems, and practical deployments.</span>
                            </a>
                        </li>
                        <li>
                            <a href="mailto:hancheng.ye@duke.edu">
                                <b>Mentorship & Advice</b>
                                <span>I keep a weekly hour for friendly chats, feedback, or career advice. Drop a note to book a time.</span>
                            </a>
                        </li>
                    </ul>
					</div>
				</div>
			</div>
		</section>
	</main>

    <!-- Light/Dark mode script -->
    <script>
      (function(){
        var root = document.documentElement;
        var btn = document.getElementById('theme-toggle');
        var userOverride = null; // track user manual toggle
        function apply(theme){
          root.setAttribute('data-theme', theme);
          try{ localStorage.setItem('theme', theme); }catch(e){}
          if (btn) btn.setAttribute('aria-pressed', String(theme === 'dark'));
          // Expose background invert flag for WebGL (invert in light mode)
          try { window.__bgInvert = (theme === 'light'); } catch(e){}
          // sync themed media (e.g., SVG object) with theme
          try {
            var obj = document.getElementById('kvcomm-graphic');
            if (obj) {
              var inject = function(){
                var doc = obj.contentDocument; if (!doc) return;
                var svg = doc.querySelector('svg'); if (!svg) return;
                var style = doc.getElementById('injected-theme-style');
                if (!style) { style = doc.createElementNS('http://www.w3.org/2000/svg','style'); style.id='injected-theme-style'; svg.appendChild(style); }
                var cssDark = 'foreignObject, foreignObject * { color:#ffffff !important; -webkit-text-fill-color:#ffffff !important; } [stroke="#081950"], [stroke="#000000"], [style*="stroke: rgb(8, 25, 80)"], [style*="stroke:#081950"], [style*="stroke: #081950"], [style*="stroke: rgb(0, 0, 0)"] { stroke:#ffffff !important; } [fill="#081950"], [fill="#000000"], [style*="fill: rgb(8, 25, 80)"], [style*="fill:#081950"], [style*="fill: #081950"], [style*="fill: rgb(0, 0, 0)"] { fill:#ffffff !important; } text { fill:#ffffff !important; stroke:none !important; }';
                var cssLight = 'foreignObject, foreignObject * { color:#081950 !important; -webkit-text-fill-color:#081950 !important; } text { fill:#081950 !important; } [stroke="#081950"], [stroke="#000000"], [style*="stroke: rgb(8, 25, 80)"], [style*="stroke:#081950"], [style*="stroke: #081950"], [style*="stroke: rgb(0, 0, 0)"] { stroke:#081950 !important; } [fill="#081950"], [fill="#000000"], [style*="fill: rgb(0, 0, 0)"], [style*="fill:#081950"], [style*="fill: #081950"] { fill:#081950 !important; }';
                style.textContent = (theme === 'dark') ? cssDark : cssLight;
              };
              if (obj.contentDocument) { inject(); }
              else { obj.addEventListener('load', inject, { once:true }); }
            }
          } catch(e){}
          // swap any images that declare light/dark sources via data attributes
          try {
            document.querySelectorAll('[data-theme-src-light][data-theme-src-dark]').forEach(function(el){
              var src = theme === 'dark' ? el.getAttribute('data-theme-src-dark') : el.getAttribute('data-theme-src-light');
              if (src && el.getAttribute('src') !== src) el.setAttribute('src', src);
            });
          } catch(e){}
        }
        var stored = null; try{ stored = localStorage.getItem('theme'); }catch(e){}
        var mql = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)');
        var prefersDark = mql && mql.matches;
        apply(stored || (prefersDark ? 'dark' : 'light'));
        if (btn) btn.addEventListener('click', function(ev){
          ev.preventDefault(); ev.stopPropagation();
          var current = root.getAttribute('data-theme') || (prefersDark ? 'dark':'light');
          userOverride = true;
          apply(current === 'dark' ? 'light' : 'dark');
        });
        if (mql && mql.addEventListener) {
          mql.addEventListener('change', function(e){
            if (!userOverride && !stored) {
              apply(e.matches ? 'dark' : 'light');
            }
          });
        }
      })();
    </script>
	<script src="js/regl.min.js"></script>

	<script type="x-shader/x-fragment" id="fragmentShader">
	#define TWO_PI 6.2831853072
	#define PI 3.14159265359

	precision highp float;

	uniform float globaltime;
	uniform vec2 resolution;
	uniform float aspect;
	uniform float scroll;
    uniform float velocity;
    uniform sampler2D texture1;
    uniform sampler2D texture2;
    uniform float mixFactor;
    uniform float invert;

    const float timescale = 0.00002;
	const float twist = 1.1;

	vec2 rotate(vec2 v, float angle) {
		float c = cos(angle);
		float s = sin(angle);
		return v * mat2(c, -s, s, c);
	}

	float nsin(float value) {
		return sin(value * TWO_PI) * 0.2 + 0.5;
	}

	void main(void) {
		float time = globaltime * timescale;
		vec2 center = vec2(sin(TWO_PI * time * 0.2), cos(TWO_PI * time * 0.2)) * nsin(time * 0.1) * 0.5;
		vec2 tx = (gl_FragCoord.xy / resolution.xy - 0.5 - center) * vec2(aspect, 1.0);
		float len = 1.0 - length(tx);
		float zoom = 0.0 + scroll - len * 2.0 * (1.0 - scroll) + len * velocity;

        vec2 uv = rotate(
                (tx + center) * vec2(0.5, -1.0) * zoom,
                twist * TWO_PI * nsin(len + time) * scroll + time
            ) + 0.4;

        vec4 img1 = texture2D(texture1, uv);
        vec4 img2 = texture2D(texture2, uv);
        vec4 imgColor = mix(img1, img2, clamp(mixFactor, 0.0, 1.0));

    if (invert > 0.5) {
        imgColor.rgb = vec3(1.0) - imgColor.rgb;
    }
    gl_FragColor = imgColor;
	}
	</script>

	<script src="js/demo.js"></script>
</body>
</html>
